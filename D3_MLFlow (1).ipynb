{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb726d0",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[**Introduction to MLFlow and MLOps**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9a400",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [**Introduction to MLFlow and MLOps**](#toc1_)    \n",
    "  - [**Why MLFlow?**](#toc1_1_)    \n",
    "  - [**What Can MLFlow Do?**](#toc1_2_)    \n",
    "- [**Hands-On MLFlow**](#toc2_)    \n",
    "  - [**Basic Usage: Autologging**](#toc2_1_)    \n",
    "  - [**Viewing Results Through the UI**](#toc2_2_)    \n",
    "  - [**Creating Experiments and Designing Logic**](#toc2_3_)    \n",
    "  - [**Where Does MLFlow Store Data?**](#toc2_4_)    \n",
    "  - [**Retrieving Models from MLFlow**](#toc2_5_)    \n",
    "  - [**Register models**](#toc2_6_)    \n",
    "  - [**Extra**](#toc2_7_)    \n",
    "    - [**Nested Experiments**](#toc2_7_1_)    \n",
    "    - [**Setting Up AWS Storage**](#toc2_7_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[**Why MLFlow?**](#toc0_)\n",
    "![MLOps](https://raw.githubusercontent.com/dsml-bootcamp-1/nbs-6-master/refs/heads/master/s-601-602/image_ops.png)\n",
    "\n",
    "Machine learning models go through several stages: data preprocessing, training, evaluation, deployment, and monitoring. \n",
    "Ensuring consistency and reproducibility across these stages is a crucial aspect of MLOps (Machine Learning Operations). \n",
    "\n",
    "MLFlow is a tool designed to streamline this process by providing a centralized system to manage and track:\n",
    "- Experiments and their results (e.g., parameters, metrics)\n",
    "- Models and their artifacts (e.g., saved files, plots, images)\n",
    "- Deployment logic for easy retrieval and deployment\n",
    "\n",
    "## <a id='toc1_2_'></a>[**What Can MLFlow Do?**](#toc0_)\n",
    "MLFlow can store:\n",
    "- **Models**: Trained models in various formats (e.g., TensorFlow, PyTorch, Scikit-Learn)\n",
    "- **Parameters**: Hyperparameters used for training\n",
    "- **Metrics**: Evaluation metrics (e.g., accuracy, loss)\n",
    "- **Artifacts**: Additional files (e.g., images, plots, HTML reports)\n",
    "- **Data**: Input and output data (e.g., CSVs, dataframes)\n",
    "\n",
    "![MLFlow Overview](../../../img/mlflow.png)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 11,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
   "id": "e6f0749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLFlow if not already installed\n",
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 12,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
   "id": "8bef13c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.2'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 12,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check mlflow version\n",
    "import mlflow\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 13,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
   "id": "1bc93ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'1.4.2'"
      ]
     },
     "execution_count": 3,
=======
       "'1.0.2'"
      ]
     },
     "execution_count": 13,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sklearn version\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 14,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
   "id": "e389cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the version is higher than 1.0.2, then downgrade (needed for autologging)\n",
    "# !pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <a id='toc2_'></a>[**Hands-On MLFlow**](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[**Basic Usage: Autologging**](#toc0_)\n",
    "\n",
    "MLFlow provides an easy-to-use `autolog` feature. Let's start by training a simple model and see how MLFlow tracks everything.\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 15,
>>>>>>> parent of f913525 (Update D3_MLFlow (1).ipynb)
   "id": "eec423d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, average_precision_score\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import plotly.express as px\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6928ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3debdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(data.target)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab01cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split - ideal?\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35189e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for Sklearn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Train a simple model\n",
    "with mlflow.start_run():\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Log metrics manually (optional)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[**Viewing Results Through the UI**](#toc0_)\n",
    "\n",
    "Start the MLFlow UI to visualize your logged experiments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef6ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your terminal (not in Jupyter)\n",
    "# mlflow ui\n",
    "\n",
    "# Can also change the port\n",
    "# mlflow ui --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125cbf86",
   "metadata": {},
   "source": [
    "\n",
    "Navigate to `http://localhost:5000` to see your experiments.\n",
    "\n",
    "![MLFlow UI Screenshot](https://mlflow.org/docs/latest/_images/quickstart-our-experiment.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_3_'></a>[**Creating Experiments and Designing Logic**](#toc0_)\n",
    "You can explicitly create experiments and log data, custom metrics, tags and other artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae3bc0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Set experiment name\\nimport mlflow.data.pandas_dataset\\n\\n\\nmlflow.set_experiment(\"breast_cancer_classification\")\\n\\n# Log parameters, metrics, and artifacts\\nwith mlflow.start_run(run_name=\"Random Forest\"):\\n    clf = RandomForestClassifier(n_estimators=100, random_state=42)\\n    clf.fit(X_train, y_train)\\n    \\n    # Set run tag\\n    mlflow.set_tag(\"features\", X_train.columns)\\n    mlflow.set_tag(\"feature_no\", len(X_train.columns))\\n    mlflow.set_tag(\"train size\", X_train.shape[0])\\n    mlflow.set_tag(\"test size\", X_test.shape[0])\\n\\n    # Log predictions\\n    predictions = pd.DataFrame(clf.predict_proba(X_test), columns=[\"prediction_score_0\", \"prediction_score_1\"])\\n    predictions[\"target\"] = y_test.values\\n    mlflow.log_table(predictions, artifact_file=\\'results/predictions.json\\')\\n    \\n    # Log custom metrics manually\\n    mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, predictions[\"prediction_score_1\"]))\\n    mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, predictions[\"prediction_score_1\"]))\\n    \\n    # Log feature importance plot\\n    fig = px.bar(x=clf.feature_importances_, y=clf.feature_names_in_)\\n    mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Set experiment name\n",
    "import mlflow.data.pandas_dataset\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"breast_cancer_classification\")\n",
    "\n",
    "# Log parameters, metrics, and artifacts\n",
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Set run tag\n",
    "    mlflow.set_tag(\"features\", X_train.columns)\n",
    "    mlflow.set_tag(\"feature_no\", len(X_train.columns))\n",
    "    mlflow.set_tag(\"train size\", X_train.shape[0])\n",
    "    mlflow.set_tag(\"test size\", X_test.shape[0])\n",
    "\n",
    "    # Log predictions\n",
    "    predictions = pd.DataFrame(clf.predict_proba(X_test), columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "    predictions[\"target\"] = y_test.values\n",
    "    mlflow.log_table(predictions, artifact_file='results/predictions.json')\n",
    "    \n",
    "    # Log custom metrics manually\n",
    "    mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "    mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "    \n",
    "    # Log feature importance plot\n",
    "    fig = px.bar(x=clf.feature_importances_, y=clf.feature_names_in_)\n",
    "    mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment setup complete. Beginning training...\n",
      "Training model with XGBoost...\n",
      "Training complete. Logging model parameters and metrics...\n",
      "Generating and logging predictions...\n",
      "Predictions logged.\n",
      "Calculating and logging metrics...\n",
      "Metrics logged.\n",
      "Generating and logging feature importance plot...\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from xgboost import XGBClassifier  # Import XGBoost\n",
    "from tqdm import tqdm  # For adding a progress bar to loops\n",
    "import warnings\n",
    "\n",
    "# Suppress XGBoost warnings (e.g., deprecated warnings)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "\n",
    "# Enable MLflow autologging for sklearn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Set experiment name\n",
    "mlflow.set_experiment(\"breast_cancer_classification\")\n",
    "\n",
    "# Inform user that experiment setup is complete\n",
    "print(\"Experiment setup complete. Beginning training...\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    print(\"Training model with XGBoost...\")\n",
    "\n",
    "    # Initialize and train the model using XGBoost with GPU acceleration (updated parameters)\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=100,             # Number of trees\n",
    "        random_state=42,              # For reproducibility\n",
    "        tree_method='hist',           # Change to 'hist' instead of deprecated 'gpu_hist'\n",
    "        device='cuda',                # Specify device for GPU\n",
    "        n_jobs=-1,                    # Use all CPU cores for data preprocessing\n",
    "        eval_metric='logloss'         # Evaluation metric for logging\n",
    "    )\n",
    "    \n",
    "    # Train the model with the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Inform user that training is complete\n",
    "    print(\"Training complete. Logging model parameters and metrics...\")\n",
    "\n",
    "    # Log essential tags\n",
    "    mlflow.set_tag(\"feature_no\", len(X_train.columns))\n",
    "\n",
    "    # Log predictions with a progress bar\n",
    "    print(\"Generating and logging predictions...\")\n",
    "    predictions = pd.DataFrame(clf.predict_proba(X_test), columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "    predictions[\"target\"] = y_test.values\n",
    "    \n",
    "    # Save and log predictions\n",
    "    predictions.to_json(\"results/predictions.json\", orient=\"records\")\n",
    "    mlflow.log_artifact(\"results/predictions.json\")\n",
    "    print(\"Predictions logged.\")\n",
    "\n",
    "    # Calculate and log custom metrics with progress updates\n",
    "    print(\"Calculating and logging metrics...\")\n",
    "    roc_auc = roc_auc_score(y_test, predictions[\"prediction_score_1\"])\n",
    "    pr_auc = average_precision_score(y_test, predictions[\"prediction_score_1\"])\n",
    "    mlflow.log_metric(\"ROC-AUC\", roc_auc)\n",
    "    mlflow.log_metric(\"PR-AUC\", pr_auc)\n",
    "    print(\"Metrics logged.\")\n",
    "\n",
    "    # Log feature importance plot with progress indication\n",
    "    print(\"Generating and logging feature importance plot...\")\n",
    "\n",
    "    # Get feature importance scores\n",
    "    feature_importance = clf.get_booster().get_score(importance_type='weight')\n",
    "    \n",
    "    # Create a sorted list of features and their importance\n",
    "    importance_values = [value for key, value in sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)]\n",
    "    feature_names = [key for key, value in sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "    # Plot feature importance\n",
    "    fig = px.bar(x=feature_names, y=importance_values, labels={'x': 'Feature', 'y': 'Importance'}, title=\"Feature Importance\")\n",
    "    \n",
    "    # Log the figure\n",
    "    mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")\n",
    "    print(\"Feature importance plot logged.\")\n",
    "\n",
    "print(\"All steps completed. Run logged in MLflow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_4_'></a>[**Where Does MLFlow Store Data?**](#toc0_)\n",
    "\n",
    "Depending on the backend setup, MLFlow stores data in:\n",
    "- **Local filesystem** (e.g., `./mlruns` directory, suitable for quick tests but slow)\n",
    "- **Local SQLite Database**: Lightweight and easy to set up\n",
    "- **Cloud storage**: AWS S3, Google Cloud Storage, etc., for large-scale deployments\n",
    "\n",
    "To configure MLFlow to use a SQLite backend:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example command to run in terminal (not in Jupyter)\n",
    "# mlflow server/ui \\\n",
    "#    --backend-store-uri sqlite:///mlflow.db \\\n",
    "#    --default-artifact-root ./mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where experiments are saved\n",
    "with mlflow.start_run(run_name=\"check_backend_uri\"):\n",
    "    mlflow.set_tag(\"new tag\", \"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking uri\n",
    "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_5_'></a>[**Retrieving Models from MLFlow**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa557085",
   "metadata": {},
   "source": [
    "Search through models - more filtering tips [here](https://mlflow.org/docs/latest/search-runs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    # search_all_experiments=True,\n",
    "    experiment_names=[\"breast_cancer_classification\"],\n",
    "    filter_string=\"\"\"metrics.`PR-AUC` > 0.7\n",
    "    \"\"\"\n",
    ")\n",
    "print(runs.shape)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ca01",
   "metadata": {},
   "source": [
    "You can load previously saved models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/{runs.run_id[0]}/model\"  # Replace <run_id> with an actual run ID\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Use the model for predictions\n",
    "predictions = loaded_model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[**Register models**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d51a5",
   "metadata": {},
   "source": [
    "This can be done either through the UI or via code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    f\"runs:/{runs.run_id[0]}/model\", \"breast-cancer-classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_7_'></a>[**Extra**](#toc0_)\n",
    "\n",
    "### <a id='toc2_7_1_'></a>[**Nested Experiments**](#toc0_)\n",
    "MLFlow allows nested runs for tracking hierarchical experiments. This can be useful if you want to group results from cross-validation folds in separate runs but keep the same attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create stratified KFold\n",
    "cross_val = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_splits = cross_val.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested cross-validation\n",
    "with mlflow.start_run(run_name=\"Random Forest\") as parent_run:\n",
    "    mlflow.log_param(\"features\", X.columns)\n",
    "    \n",
    "    for i, (train_split, test_split) in enumerate(cv_splits):\n",
    "        with mlflow.start_run(run_name=f\"Random Forest {i}\", nested=True):\n",
    "            X_train, y_train = X.iloc[train_split, :], y[train_split]\n",
    "            X_test, y_test = X.iloc[test_split, :], y[test_split]\n",
    "            \n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Set run tag\n",
    "            mlflow.set_tag(\"features\", X_train.columns)\n",
    "            mlflow.set_tag(\"feature_no\", len(X_train.columns))\n",
    "            mlflow.set_tag(\"train size\", X_train.shape[0])\n",
    "            mlflow.set_tag(\"test size\", X_test.shape[0])\n",
    "\n",
    "            # Log predictions\n",
    "            predictions = pd.DataFrame(clf.predict_proba(X_test), columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "            predictions[\"target\"] = y_test\n",
    "            mlflow.log_table(predictions, artifact_file='results/predictions.json')\n",
    "\n",
    "            # Log custom metrics manually\n",
    "            mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "            mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "\n",
    "            # Log feature importance plot\n",
    "            fig = px.bar(x=clf.feature_importances_, y=clf.feature_names_in_)\n",
    "            mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc2_7_2_'></a>[**Setting Up AWS Storage**](#toc0_)\n",
    "You can configure MLFlow to use AWS Postgresql database (either on RDS or Redshift) as metadata store and AWS S3 as the artifact storage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# !mlflow server \\\n",
    "#     --backend-store-uri 'postgresql://user_name:password@link_to_your_aws_postgresql_db:port' \\\n",
    "#     --default-artifact-root s3://your-bucket-name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
