{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb726d0",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[**Introduction to MLFlow and MLOps**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9a400",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [**Introduction to MLFlow and MLOps**](#toc1_)    \n",
    "  - [**Why MLFlow?**](#toc1_1_)    \n",
    "  - [**What Can MLFlow Do?**](#toc1_2_)    \n",
    "- [**Hands-On MLFlow**](#toc2_)    \n",
    "  - [**Basic Usage: Autologging**](#toc2_1_)    \n",
    "  - [**Viewing Results Through the UI**](#toc2_2_)    \n",
    "  - [**Creating Experiments and Designing Logic**](#toc2_3_)    \n",
    "  - [**Where Does MLFlow Store Data?**](#toc2_4_)    \n",
    "  - [**Retrieving Models from MLFlow**](#toc2_5_)    \n",
    "  - [**Register models**](#toc2_6_)    \n",
    "  - [**Extra**](#toc2_7_)    \n",
    "    - [**Nested Experiments**](#toc2_7_1_)    \n",
    "    - [**Setting Up AWS Storage**](#toc2_7_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[**Why MLFlow?**](#toc0_)\n",
    "![MLOps](https://raw.githubusercontent.com/dsml-bootcamp-1/nbs-6-master/refs/heads/master/s-601-602/image_ops.png)\n",
    "\n",
    "Machine learning models go through several stages: data preprocessing, training, evaluation, deployment, and monitoring. \n",
    "Ensuring consistency and reproducibility across these stages is a crucial aspect of MLOps (Machine Learning Operations). \n",
    "\n",
    "MLFlow is a tool designed to streamline this process by providing a centralized system to manage and track:\n",
    "- Experiments and their results (e.g., parameters, metrics)\n",
    "- Models and their artifacts (e.g., saved files, plots, images)\n",
    "- Deployment logic for easy retrieval and deployment\n",
    "\n",
    "## <a id='toc1_2_'></a>[**What Can MLFlow Do?**](#toc0_)\n",
    "MLFlow can store:\n",
    "- **Models**: Trained models in various formats (e.g., TensorFlow, PyTorch, Scikit-Learn)\n",
    "- **Parameters**: Hyperparameters used for training\n",
    "- **Metrics**: Evaluation metrics (e.g., accuracy, loss)\n",
    "- **Artifacts**: Additional files (e.g., images, plots, HTML reports)\n",
    "- **Data**: Input and output data (e.g., CSVs, dataframes)\n",
    "\n",
    "![MLFlow Overview](../../../img/mlflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0749e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.10.15)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\Marc Jay\\Ironhack\\ironhack-v4-data-lessons\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Install MLFlow if not already installed\n",
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mlflow version\n",
    "import mlflow\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc93ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sklearn version\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the version is higher than 1.0.2, then downgrade (needed for autologging)\n",
    "# !pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <a id='toc2_'></a>[**Hands-On MLFlow**](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[**Basic Usage: Autologging**](#toc0_)\n",
    "\n",
    "MLFlow provides an easy-to-use `autolog` feature. Let's start by training a simple model and see how MLFlow tracks everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec423d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import plotly.express as px\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6928ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3debdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(data.target)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab01cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split - ideal?\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35189e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for Sklearn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Train a simple model\n",
    "with mlflow.start_run():\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Log metrics manually (optional)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[**Viewing Results Through the UI**](#toc0_)\n",
    "\n",
    "Start the MLFlow UI to visualize your logged experiments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your terminal (not in Jupyter)\n",
    "# mlflow ui\n",
    "\n",
    "# Can also change the port\n",
    "# mlflow ui --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125cbf86",
   "metadata": {},
   "source": [
    "\n",
    "Navigate to `http://localhost:5000` to see your experiments.\n",
    "\n",
    "![MLFlow UI Screenshot](https://mlflow.org/docs/latest/_images/quickstart-our-experiment.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_3_'></a>[**Creating Experiments and Designing Logic**](#toc0_)\n",
    "You can explicitly create experiments and log data, custom metrics, tags and other artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment name\n",
    "import mlflow.data.pandas_dataset\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"breast_cancer_classification\")\n",
    "\n",
    "# Log parameters, metrics, and artifacts\n",
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Set run tag\n",
    "    mlflow.set_tag(\"features\", X_train.columns)\n",
    "    mlflow.set_tag(\"feature_no\", len(X_train.columns))\n",
    "    mlflow.set_tag(\"train size\", X_train.shape[0])\n",
    "    mlflow.set_tag(\"test size\", X_test.shape[0])\n",
    "\n",
    "    # Log predictions\n",
    "    predictions = pd.DataFrame(clf.predict_proba(X_test), columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "    predictions[\"target\"] = y_test.values\n",
    "    mlflow.log_table(predictions, artifact_file='results/predictions.json')\n",
    "    \n",
    "    # Log custom metrics manually\n",
    "    mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "    mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "    \n",
    "    # Log feature importance plot\n",
    "    fig = px.bar(x=clf.feature_importances_, y=clf.feature_names_in_)\n",
    "    mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_4_'></a>[**Where Does MLFlow Store Data?**](#toc0_)\n",
    "\n",
    "Depending on the backend setup, MLFlow stores data in:\n",
    "- **Local filesystem** (e.g., `./mlruns` directory, suitable for quick tests but slow)\n",
    "- **Local SQLite Database**: Lightweight and easy to set up\n",
    "- **Cloud storage**: AWS S3, Google Cloud Storage, etc., for large-scale deployments\n",
    "\n",
    "To configure MLFlow to use a SQLite backend:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example command to run in terminal (not in Jupyter)\n",
    "# mlflow server/ui \\\n",
    "#    --backend-store-uri sqlite:///mlflow.db \\\n",
    "#    --default-artifact-root ./mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where experiments are saved\n",
    "with mlflow.start_run(run_name=\"check_backend_uri\"):\n",
    "    mlflow.set_tag(\"new tag\", \"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking uri\n",
    "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_5_'></a>[**Retrieving Models from MLFlow**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa557085",
   "metadata": {},
   "source": [
    "Search through models - more filtering tips [here](https://mlflow.org/docs/latest/search-runs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    # search_all_experiments=True,\n",
    "    experiment_names=[\"breast_cancer_classification\"],\n",
    "    filter_string=\"\"\"metrics.`PR-AUC` > 0.7\n",
    "    \"\"\"\n",
    ")\n",
    "print(runs.shape)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ca01",
   "metadata": {},
   "source": [
    "You can load previously saved models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/{runs.run_id[0]}/model\"  # Replace <run_id> with an actual run ID\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Use the model for predictions\n",
    "predictions = loaded_model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[**Register models**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d51a5",
   "metadata": {},
   "source": [
    "This can be done either through the UI or via code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    f\"runs:/{runs.run_id[0]}/model\", \"breast-cancer-classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_7_'></a>[**Extra**](#toc0_)\n",
    "\n",
    "### <a id='toc2_7_1_'></a>[**Nested Experiments**](#toc0_)\n",
    "MLFlow allows nested runs for tracking hierarchical experiments. This can be useful if you want to group results from cross-validation folds in separate runs but keep the same attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create stratified KFold\n",
    "cross_val = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_splits = cross_val.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested cross-validation\n",
    "with mlflow.start_run(run_name=\"Random Forest\") as parent_run:\n",
    "    mlflow.log_param(\"features\", X.columns)\n",
    "    \n",
    "    for i, (train_split, test_split) in enumerate(cv_splits):\n",
    "        with mlflow.start_run(run_name=f\"Random Forest {i}\", nested=True):\n",
    "            X_train, y_train = X.iloc[train_split, :], y[train_split]\n",
    "            X_test, y_test = X.iloc[test_split, :], y[test_split]\n",
    "            \n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Set run tag\n",
    "            mlflow.set_tag(\"features\", X_train.columns)\n",
    "            mlflow.set_tag(\"feature_no\", len(X_train.columns))\n",
    "            mlflow.set_tag(\"train size\", X_train.shape[0])\n",
    "            mlflow.set_tag(\"test size\", X_test.shape[0])\n",
    "\n",
    "            # Log predictions\n",
    "            predictions = pd.DataFrame(clf.predict_proba(X_test), columns=[\"prediction_score_0\", \"prediction_score_1\"])\n",
    "            predictions[\"target\"] = y_test\n",
    "            mlflow.log_table(predictions, artifact_file='results/predictions.json')\n",
    "\n",
    "            # Log custom metrics manually\n",
    "            mlflow.log_metric(\"ROC-AUC\", roc_auc_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "            mlflow.log_metric(\"PR-AUC\", average_precision_score(y_test, predictions[\"prediction_score_1\"]))\n",
    "\n",
    "            # Log feature importance plot\n",
    "            fig = px.bar(x=clf.feature_importances_, y=clf.feature_names_in_)\n",
    "            mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc2_7_2_'></a>[**Setting Up AWS Storage**](#toc0_)\n",
    "You can configure MLFlow to use AWS Postgresql database (either on RDS or Redshift) as metadata store and AWS S3 as the artifact storage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# !mlflow server \\\n",
    "#     --backend-store-uri 'postgresql://user_name:password@link_to_your_aws_postgresql_db:port' \\\n",
    "#     --default-artifact-root s3://your-bucket-name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
